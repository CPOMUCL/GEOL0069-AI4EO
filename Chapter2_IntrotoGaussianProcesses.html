

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Introduction to Gaussian Processes &#8212; GEOL0069 Guide Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Chapter2_IntrotoGaussianProcesses';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introduction to GPSat" href="Chapter_2_Intro_to_GPSat.html" />
    <link rel="prev" title="References" href="References1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to GEOL0069 AI for Earth Observation
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3APreparation.html">Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3AIRIS.html">Introduction to Intelligently Reinforced Image Segmentation (IRIS)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3AML.html">Introduction to AI/Machine Learning</a></li>

<li class="toctree-l1"><a class="reference internal" href="Chapter_1_Sea_ice_and_Lead_Classification.html">Sea-ice and Lead Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_1_AI_Algorithms.html">AI/Machine Learning Implementation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3AFetching_Data.html">Data Fetching</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_1_rollout_3.html">Roll-out on a Full Image</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter1_Data_Colocating_S2_S3_3.html">Colocating Sentinel-3 OLCI/SRAL and Sentinal-2 Optical Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter1%3AUnsupervised_Learning_Methods.html">Unsupervised Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter1%3ARegression.html">Regression Techniques for Predictive Analysis</a></li>

<li class="toctree-l1"><a class="reference internal" href="Chapter1%3AAligning_Images.html">Aligning Sentinel-2 and Sentinel-3 OLCI Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter1%3AColocating_data.html">Colocate Sentinel-2 and Sentinel-3 Imagery</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter1%3ARegression_Part2.html">Application of Regression Techniques in Satellite Imagery Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="References1.html">References</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 7</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction to Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_2_Intro_to_GPSat.html">Introduction to GPSat</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 8</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter_2_SLA_GPSat_William.html">Interpolation of Sea Level Anomaly using GPSat</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_2_GPSat_along_track-2.html">Along track interpolation</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 9</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ExplainableAI.html">Explainable AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="ExplainableAI_Part2.html">Explainable AI Part 2</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FChapter2_IntrotoGaussianProcesses.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Chapter2_IntrotoGaussianProcesses.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to Gaussian Processes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview-and-definition">Overview and Definition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#some-intuitive-examples-zhang2023dive">Some intuitive examples <span class="xref cite">zhang2023dive</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-framework-zhang2023dive-bishop2006pattern">Mathematical Framework <span class="xref cite">zhang2023dive,bishop2006pattern</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">Basic Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-functions-kernels">Covariance Functions (Kernels)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-and-variance">Mean and Variance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-process-a-logical-processing-chain">Gaussian Process - A Logical Processing Chain</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-gaussian-processes">
<h1>Introduction to Gaussian Processes<a class="headerlink" href="#introduction-to-gaussian-processes" title="Permalink to this heading">#</a></h1>
<section id="overview-and-definition">
<h2>Overview and Definition<a class="headerlink" href="#overview-and-definition" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://drive.google.com/drive/folders/1evG23O-nAj9CLciG3XbgUKCVQiPS-jO3?usp=sharing">Week 7</a></p>
<p>In week 7, we will dive into Gaussian Processes in a greater detail. From previous weeks, we know that machine learning often focuses on extracting numerous, complex parameters from data, like neural network weights, which can be hard to interpret. Gaussian processes differ by allowing us to directly consider the broad characteristics of potential functions fitting our data, such as their variability, periodicity, or other structural features. They enable the incorporation of these insights into our models by defining a Gaussian distribution over the functions that best match our observations. Essentially, a Gaussian Process is a collection of random variables, any finite number of which have a joint Gaussian distribution. This makes GPs a natural choice for modeling distributions over functions. They are particularly powerful for regression problems, where the goal is to predict continuous outcomes.</p>
</section>
<section id="some-intuitive-examples-zhang2023dive">
<h2>Some intuitive examples <span id="id1">[<a class="reference internal" href="References1.html#id17" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span><a class="headerlink" href="#some-intuitive-examples-zhang2023dive" title="Permalink to this heading">#</a></h2>
<p>In the given dataset, we have a series of regression targets, denoted as <span class="math notranslate nohighlight">\(y\)</span>, which are associated with their corresponding inputs, <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Generating sample data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># For reproducibility</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>  <span class="c1"># 15 data points between 0 and 20</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Observations with noise</span>

<span class="c1"># Plotting the data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># Set the figure size</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>  <span class="c1"># Scatter plot of observations</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Observations y&#39;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Inputs x&#39;</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Observations y&#39;</span><span class="p">)</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Adding a grid for better readability</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Display the plot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/52023c9cab58f5d63072268e4eaacd28dff4d4c5fa40e02b9f2d62f761be8109.png" src="_images/52023c9cab58f5d63072268e4eaacd28dff4d4c5fa40e02b9f2d62f761be8109.png" />
</div>
</div>
<p>To model our data using a Gaussian process, we first establish a prior reflecting plausible function behaviors, like their variation with respect to the inputs. The samples displayed here illustrate this prior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">GPy</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">GPy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define the kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>

<span class="c1"># Define the range of the input space</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create a Gaussian process regression model</span>
<span class="n">gp</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPRegression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">kernel</span><span class="p">)</span>

<span class="c1"># Sample functions from the Gaussian process</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">Y_samples</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">posterior_samples_f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>

<span class="c1"># Plot the sampled functions</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_samples</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Display the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d345de9d2bf9eacdc0a8e1e68685d245c18462971ddd38a9c9ff796acb321375.png" src="_images/d345de9d2bf9eacdc0a8e1e68685d245c18462971ddd38a9c9ff796acb321375.png" />
</div>
</div>
<p>Now we’ve conditioned on the data, we can use prior to infer about the posterior distribution over functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">GPy</span>

<span class="c1"># Set the random seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Generating sample data</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>  <span class="c1"># 15 data points between 0 and 20</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Observations with noise</span>

<span class="c1"># Reshape x and y for GPy requirements</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Define the kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="mf">2.</span><span class="p">)</span>

<span class="c1"># Create a GP model</span>
<span class="n">gp_model</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPRegression</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>

<span class="c1"># Optimise the model</span>
<span class="n">gp_model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Predicting on a dense set of points to get smooth sample functions</span>
<span class="n">x_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_pred</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Draw samples from the posterior</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">posterior_samples_f</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mean Prediction&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">samples</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Input x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Output y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample Posterior Functions from a Gaussian Process&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "05756d6ba8e64a1ab35e235a39848820", "version_major": 2, "version_minor": 0}</script><img alt="_images/9255744b86e8422cfa2847a12cd52492de21faa94d8819204f2584b16b26ee7a.png" src="_images/9255744b86e8422cfa2847a12cd52492de21faa94d8819204f2584b16b26ee7a.png" />
</div>
</div>
<p>The plot below illustrates the epistemic uncertainty in our predictions, showing where there’s more potential variability in the underlying true function. This type of uncertainty decreases as we gather more data. The shaded area represents a 95% credible interval around the mean prediction, calculated as twice the posterior standard deviation, indicating where the true function values likely fall for any input <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicting on a dense set of points to get smooth sample functions</span>
<span class="n">x_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_pred</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Draw samples from the posterior</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">gp_model</span><span class="o">.</span><span class="n">posterior_samples_f</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>

<span class="c1"># Plot the mean prediction with the observed data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mean Prediction&#39;</span><span class="p">)</span>

<span class="c1"># Plot the uncertainty (95% credible interval)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_pred</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> 
                 <span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> 
                 <span class="p">(</span><span class="n">y_pred</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> 
                 <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% Credible Interval&#39;</span><span class="p">)</span>

<span class="c1"># Plot the samples from the posterior</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_pred</span><span class="p">,</span> <span class="n">samples</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Input x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Output y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample Posterior Functions from a Gaussian Process&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/732f3fba6c96befa0bbafa18c39b82e5cdab8279ef88b9d8faef5aded54df523.png" src="_images/732f3fba6c96befa0bbafa18c39b82e5cdab8279ef88b9d8faef5aded54df523.png" />
</div>
</div>
<p>Now, you should get some ideas of how GP works roughly, from the prior to the posterior distributions over the functions.</p>
</section>
<section id="mathematical-framework-zhang2023dive-bishop2006pattern">
<h2>Mathematical Framework <span id="id2">[<a class="reference internal" href="References1.html#id4" title="Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning. Volume 4. Springer, 2006.">Bishop and Nasrabadi, 2006</a>, <a class="reference internal" href="References1.html#id17" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span><a class="headerlink" href="#mathematical-framework-zhang2023dive-bishop2006pattern" title="Permalink to this heading">#</a></h2>
<section id="basic-concepts">
<h3>Basic Concepts<a class="headerlink" href="#basic-concepts" title="Permalink to this heading">#</a></h3>
<p>A Gaussian Process (GP) is essentially an advanced form of a Gaussian (or normal) distribution, but instead of being over simple variables, it’s over functions. Imagine a GP as a method to predict or estimate a function based on known data points.</p>
<p>In mathematical terms, a GP is defined for a set of function values, where these values follow a Gaussian distribution. Specifically, for any selection of points from a set <span class="math notranslate nohighlight">\(X\)</span>, the values that a function <span class="math notranslate nohighlight">\(f\)</span> takes at these points follow a joint Gaussian distribution.</p>
<p>The key to understanding GPs lies in two main concepts:</p>
<ol class="arabic simple">
<li><p><strong>Mean Function</strong>: <span class="math notranslate nohighlight">\(m: X \rightarrow Y\)</span>. This function gives the average expected value of the function <span class="math notranslate nohighlight">\(f(x)\)</span> at each point <span class="math notranslate nohighlight">\(x\)</span> in the set <span class="math notranslate nohighlight">\(X\)</span>. It’s like predicting the average outcome based on the known data.</p></li>
<li><p><strong>Kernel or Covariance Function</strong>: <span class="math notranslate nohighlight">\(k: X \times X \rightarrow Y\)</span>. This function tells us how much two points in the set <span class="math notranslate nohighlight">\(X\)</span> are related or how they influence each other. It’s a way of understanding the relationship or similarity between different points in our data.</p></li>
</ol>
<p>To apply GPs in a practical setting, we typically select several points in our input space <span class="math notranslate nohighlight">\(X\)</span>, calculate the mean and covariance at these points, and then use this information to make predictions. This process involves working with vectors and matrices derived from the mean and kernel functions to graphically represent the Gaussian Process.</p>
<p><strong>Note</strong>: In mathematical notation, for a set of points <span class="math notranslate nohighlight">\( \mathbf{X}=x_1, \ldots, x_N \)</span>, the mean vector <span class="math notranslate nohighlight">\( \mathbf{m} \)</span> and covariance matrix <span class="math notranslate nohighlight">\( \mathbf{K} \)</span> are constructed from these points using the mean and kernel functions. Each element of <span class="math notranslate nohighlight">\( \mathbf{m} \)</span> and <span class="math notranslate nohighlight">\( \mathbf{K} \)</span> corresponds to the mean and covariance values calculated for these points.</p>
</section>
<section id="covariance-functions-kernels">
<h3>Covariance Functions (Kernels)<a class="headerlink" href="#covariance-functions-kernels" title="Permalink to this heading">#</a></h3>
<p>Covariance functions, or kernels, determine how a Gaussian Process (GP) generalizes from observed data. They are fundamental in defining the GP’s behavior.</p>
<ul>
<li><p><strong>Concept and Mathematical Representation</strong>:</p>
<ul class="simple">
<li><p>Kernels measure the similarity between points in input space. The function <span class="math notranslate nohighlight">\(k(x, x')\)</span> computes the covariance between the outputs corresponding to inputs <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(x'\)</span>.</p></li>
<li><p>For example, the Radial Basis Function (RBF) kernel is defined as <span class="math notranslate nohighlight">\(k(x, x') = \exp\left(-\frac{1}{2l^2} \| x - x' \|^2\right)\)</span>, where <span class="math notranslate nohighlight">\(l\)</span> is the length-scale parameter.</p></li>
</ul>
</li>
<li><p><strong>Types of Kernels and Their Uses</strong>:</p>
<ul class="simple">
<li><p><strong>RBF Kernel</strong>: Suited for smooth functions. The length-scale <span class="math notranslate nohighlight">\(l\)</span> controls how rapidly the correlation decreases with distance.</p></li>
<li><p><strong>Linear Kernel</strong>: <span class="math notranslate nohighlight">\(k(x, x') = x^T x'\)</span>, useful for linear relationships.</p></li>
<li><p><strong>Periodic Kernels</strong>: Capture periodic behavior, expressed as <span class="math notranslate nohighlight">\(k(x, x') = \exp\left(-\frac{2\sin^2(\pi|x - x'|)}{l^2}\right)\)</span>.</p></li>
</ul>
<p>In our context, the <strong>RBF Kernel</strong> will be used in most cases. More practical examples are in future chapters.</p>
</li>
<li><p><strong>Hyperparameter Tuning</strong>:</p>
<ul class="simple">
<li><p>Hyperparameters like <span class="math notranslate nohighlight">\(l\)</span> in RBF or periodicity in periodic kernels crucially affect GP modeling. Their tuning, often through methods like maximum likelihood, adapts the GP to the specific data structure.</p></li>
</ul>
</li>
<li><p><strong>Choosing the Right Kernel</strong>:</p>
<ul class="simple">
<li><p>Involves understanding data characteristics. RBF is a default choice for many, but specific data patterns might necessitate different or combined kernels.</p></li>
</ul>
</li>
</ul>
</section>
<section id="mean-and-variance">
<h3>Mean and Variance<a class="headerlink" href="#mean-and-variance" title="Permalink to this heading">#</a></h3>
<p>The mean and variance functions in a Gaussian Process (GP) provide predictions and their uncertainties.</p>
<ul class="simple">
<li><p><strong>Mean Function - Mathematical Explanation</strong>:</p>
<ul>
<li><p>The mean function, often denoted as <span class="math notranslate nohighlight">\(m(x)\)</span>, gives the expected value of the function at each point. A common assumption is <span class="math notranslate nohighlight">\(m(x) = 0\)</span>, although non-zero means can incorporate prior trends.</p></li>
</ul>
</li>
<li><p><strong>Variance Function - Quantifying Uncertainty</strong>:</p>
<ul>
<li><p>The variance, denoted as <span class="math notranslate nohighlight">\(\sigma^2(x)\)</span>, represents the uncertainty in predictions. It’s calculated as <span class="math notranslate nohighlight">\(\sigma^2(x) = k(x, x) - K(X, x)^T[K(X, X) + \sigma^2_nI]^{-1}K(X, x)\)</span>, where <span class="math notranslate nohighlight">\(K(X, x)\)</span> and <span class="math notranslate nohighlight">\(K(X, X)\)</span> are covariance matrices, and <span class="math notranslate nohighlight">\(\sigma^2_n\)</span> is the noise term.</p></li>
</ul>
</li>
<li><p><strong>Practical Interpretation</strong>:</p>
<ul>
<li><p>High variance at a point suggests low confidence in predictions there, guiding decisions on where more data might be needed or caution in using the predictions.</p></li>
</ul>
</li>
<li><p><strong>Mean and Variance in Predictions</strong>:</p>
<ul>
<li><p>Together, they provide a probabilistic forecast. The mean offers the best guess, while the variance indicates reliability. This duo is key in risk-sensitive applications.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="gaussian-process-a-logical-processing-chain">
<h2>Gaussian Process - A Logical Processing Chain<a class="headerlink" href="#gaussian-process-a-logical-processing-chain" title="Permalink to this heading">#</a></h2>
<p>Just like other machine learning algorithm, the logical processing chain for a Gaussian Process (GP) involves thoese key steps:</p>
<ol class="arabic simple">
<li><p><strong>Defining the Problem</strong>:</p>
<ul class="simple">
<li><p>Start by identifying the problem to be solved using GP, such as regression, classification, or another task where predicting a continuous function is required.</p></li>
</ul>
</li>
<li><p><strong>Data Preparation</strong>:</p>
<ul class="simple">
<li><p>Organise the data into a suitable format. This includes input features and corresponding target values.</p></li>
</ul>
</li>
<li><p><strong>Choosing a Kernel Function</strong>:</p>
<ul class="simple">
<li><p>Select an appropriate kernel (covariance function) for the GP. The choice depends on the nature of the data and the problem.</p></li>
</ul>
</li>
<li><p><strong>Setting the Hyperparameters</strong>:</p>
<ul class="simple">
<li><p>Initialise hyperparameters for the chosen kernel. These can include parameters like length-scale in the RBF kernel or periodicity in a periodic kernel.</p></li>
</ul>
</li>
<li><p><strong>Model Training</strong>:</p>
<ul class="simple">
<li><p>Train the GP model by optimizing the hyperparameters. This usually involves maximizing the likelihood of the observed data under the GP model.</p></li>
</ul>
</li>
<li><p><strong>Prediction</strong>:</p>
<ul class="simple">
<li><p>Use the trained GP model to make predictions. This involves computing the mean and variance of the GP’s posterior distribution.</p></li>
</ul>
</li>
<li><p><strong>Model Evaluation</strong>:</p>
<ul class="simple">
<li><p>Evaluate the model’s performance using suitable metrics. For regression, this could be RMSE or MAE; for classification, accuracy or AUC.</p></li>
</ul>
</li>
<li><p><strong>Refinement</strong>:</p>
<ul class="simple">
<li><p>Based on the evaluation, refine the model by adjusting hyperparameters or kernel choice, and retrain if necessary.</p></li>
</ul>
</li>
</ol>
<p>This chain provides a comprehensive overview of the steps involved in applying Gaussian Processes to a problem, from initial setup to prediction and evaluation.</p>
<p>With a foundational understanding of Gaussian Processes (GP) established, we are now ready to delve deeper into the subject. Let’s now dive into details by following notebooks:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_gaussian-processes/gp-intro.ipynb">Introduction to Gaussian Processes</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_gaussian-processes/gp-priors.ipynb">Gaussian Process Priors</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_gaussian-processes/gp-inference.ipynb">Gaussian Process Inference</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/CPOMUCL/GPSat/blob/main/docs/notebooks/gp_regression.ipynb">GPSat: GP Regression</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/CPOMUCL/GPSat/blob/main/docs/notebooks/using_gpus.ipynb">GPSat: Using GPUs</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/CPOMUCL/GPSat/blob/main/docs/notebooks/1d_local_expert_model_part_1.ipynb">GPSat: 1-D Local Expert Model Part-1</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/CPOMUCL/GPSat/blob/main/docs/notebooks/1d_local_expert_model_part_2.ipynb">GPSat: 1-D Local Expert Model Part-2</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/CPOMUCL/GPSat/blob/main/docs/notebooks/inline_example.ipynb">GPSat: Inline Example</a></p></li>
</ul>
<p>Before running any of the GPSat notebook above, please run the following cells to install GPSat package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">google.colab</span>
    <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># TODO: allow for mounting of gdrive</span>
<span class="c1"># TODO: allow for checking out a branch</span>

<span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">re</span>

    <span class="c1"># change to working directory</span>
    <span class="n">work_dir</span> <span class="o">=</span> <span class="s2">&quot;/content&quot;</span>
    
    <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">work_dir</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;workspace directory: </span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s2"> does not exist&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">work_dir</span><span class="p">)</span>
    
    <span class="c1"># clone repository</span>
    <span class="o">!</span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/CPOMUCL/GPSat.git

    <span class="n">repo_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">work_dir</span><span class="p">,</span> <span class="s2">&quot;GPSat&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;changing directory to: </span><span class="si">{</span><span class="n">repo_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">repo_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="References1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">References</p>
      </div>
    </a>
    <a class="right-next"
       href="Chapter_2_Intro_to_GPSat.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to GPSat</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview-and-definition">Overview and Definition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#some-intuitive-examples-zhang2023dive">Some intuitive examples <span class="xref cite">zhang2023dive</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-framework-zhang2023dive-bishop2006pattern">Mathematical Framework <span class="xref cite">zhang2023dive,bishop2006pattern</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">Basic Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-functions-kernels">Covariance Functions (Kernels)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-and-variance">Mean and Variance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-process-a-logical-processing-chain">Gaussian Process - A Logical Processing Chain</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michel Tsamados/Weibin Chen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>