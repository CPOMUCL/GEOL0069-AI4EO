

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>AI/Machine Learning Implementation &#8212; GEOL0069 Guide Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Chapter 1:AI_Algorithms';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to GEOL0069 AI for Earth Observation
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3APreparation.html">Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3AIRIS.html">Introduction to Intelligently Reinforced Image Segmentation (IRIS)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3AML.html">Introduction to AI/Machine Learning</a></li>

<li class="toctree-l1"><a class="reference internal" href="Chapter_1_Sea_ice_and_Lead_Classification.html">Sea-ice and Lead Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_1_AI_Algorithms.html">AI/Machine Learning Implementation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter%201%3AFetching_Data.html">Data Fetching</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_1_rollout_3.html">Roll-out on a Full Image</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter1_Data_Colocating_S2_S3_3.html">Colocating Sentinel-3 OLCI/SRAL and Sentinal-2 Optical Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter1_Unsupervised_Learning_Methods_2.html">Unsupervised Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter1_Regression.html">Regression Techniques for Predictive Analysis</a></li>

<li class="toctree-l1"><a class="reference internal" href="Chapter1%3AAligning_Images.html">Aligning Sentinel-2 and Sentinel-3 OLCI Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter1%3AColocating_data.html">Colocate Sentinel-2 and Sentinel-3 Imagery</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter1%3ARegression_Part2.html">Application of Regression Techniques in Satellite Imagery Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="References1.html">References</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 7</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter2_IntrotoGaussianProcesses.html">Introduction to Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_2_Intro_to_GPSat.html">Introduction to GPSat</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 8</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Chapter_2_SLA_GPSat_William.html">Interpolation of Sea Level Anomaly using GPSat</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chapter_2_GPSat_along_track-2.html">Along track interpolation</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 9</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ExplainableAI.html">Explainable AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="ExplainableAI_Part2.html">Explainable AI Part 2</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FChapter 1:AI_Algorithms.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Chapter 1:AI_Algorithms.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>AI/Machine Learning Implementation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-data">Loading the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-cnns">Introduction to CNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-cnn-for-image-data">Why CNN for Image Data?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-components-of-cnn">Key Components of CNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-cnns-learn-spatial-hierarchies">How CNNs Learn Spatial Hierarchies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-of-cnns">Advantages of CNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-code-implementation">Basic Code Implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests">Random Forests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-learning">1. <strong>Ensemble Learning</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-trees">2. <strong>Decision Trees</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap-aggregating-bagging">3. <strong>Bootstrap Aggregating (Bagging)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-randomness">4. <strong>Feature Randomness</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages">Advantages</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-in-python-using-scikit-learn">Implementation in Python (Using Scikit-learn)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vision-transformer-vit">Vision Transformer (ViT)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Theoretical Foundations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation-of-images">1. <strong>Tokenisation of Images</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#position-embeddings">2. <strong>Position Embeddings</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformer-architecture">3. <strong>Transformer Architecture</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-head">4. <strong>Classification Head</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-of-vit">Advantages of ViT</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection-and-cross-validation">Model Selection and Cross-validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-models">Deep Learning Models:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#traditional-ml-models">Traditional ML Models:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overlap-best-practices">Overlap &amp; Best Practices:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-cross-validation-bishop2006pattern">What is Cross-Validation? <span class="xref cite">bishop2006pattern</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-cross-validation-bishop2006pattern">K-Fold Cross-Validation <span class="xref cite">bishop2006pattern</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search">Grid Search</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ai-machine-learning-implementation">
<h1>AI/Machine Learning Implementation<a class="headerlink" href="#ai-machine-learning-implementation" title="Permalink to this heading">#</a></h1>
<p>📘 <strong>Interactive Version</strong>: For a hands-on experience with this chapter’s content, access the interactive notebook in <a class="reference external" href="https://drive.google.com/file/d/1OsVukpWf2-oUD0sr7xOI1UZ0cJVt8lvE/view?usp=sharing">Google Colab</a>.</p>
<p>In this section, we delve into the practical application of prominent AI and machine learning algorithms using the datasets curated in the preceding chapters. While an exhaustive theoretical comprehension isn’t mandatory, a foundational grasp of the underlying principles and confidence in their basic implementation will be advantageous.
The main task focus on this chapter will be classification because we are doing surface discrimination . We will come across regression in future chapters.</p>
<section id="loading-the-data">
<h2>Loading the data<a class="headerlink" href="#loading-the-data" title="Permalink to this heading">#</a></h2>
<p>From the previous notebook, you should have your training and testing data ready from this code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s1">&#39;X_train_balanced.npy&#39;</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s1">&#39;X_test_balanced.npy&#39;</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s1">&#39;y_train_balanced.npy&#39;</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s1">&#39;y_test_balanced.npy&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="convolutional-neural-networks-cnn">
<h2>Convolutional Neural Networks (CNN)<a class="headerlink" href="#convolutional-neural-networks-cnn" title="Permalink to this heading">#</a></h2>
<section id="introduction-to-cnns">
<h3>Introduction to CNNs<a class="headerlink" href="#introduction-to-cnns" title="Permalink to this heading">#</a></h3>
<p>Convolutional Neural Networks, commonly known as CNNs, are a class of deep neural networks specially designed to process data with grid-like topology, such as images <span id="id1">[<a class="reference internal" href="References1.html#id2" title="Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.deeplearningbook.org.">Goodfellow <em>et al.</em>, 2016</a>, <a class="reference internal" href="References1.html#id3" title="Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444, May 2015. doi:10.1038/nature14539.">LeCun <em>et al.</em>, 2015</a>]</span>. Originating from the visual cortex’s biological processes, CNNs are revolutionising the way we understand and interpret visual data.</p>
</section>
<section id="why-cnn-for-image-data">
<h3>Why CNN for Image Data?<a class="headerlink" href="#why-cnn-for-image-data" title="Permalink to this heading">#</a></h3>
<p>Traditional neural networks, when used for images, suffer from two main issues:</p>
<ul class="simple">
<li><p><strong>Too many parameters</strong>: For a simple 256x256 colored image, an input layer would have (256 * 256 * 3 = 196,608) neurons, leading to an enormous number of parameters even in the first hidden layer.</p></li>
<li><p><strong>Loss of spatial information</strong>: Flattening an image into a vector for traditional neural networks can lose the spatial hierarchies and patterns in the image, which are often crucial for understanding and interpreting visual data.</p></li>
</ul>
<p>CNNs address both issues by introducing convolutions.</p>
</section>
<section id="key-components-of-cnn">
<h3>Key Components of CNN<a class="headerlink" href="#key-components-of-cnn" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Convolutional Layer</strong> <span id="id2">[<a class="reference internal" href="References1.html#id3" title="Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444, May 2015. doi:10.1038/nature14539.">LeCun <em>et al.</em>, 2015</a>]</span>: This is the core building block of a CNN. It slides a filter (smaller in size than the input data) over the input data (like an image) to produce a feature map or convolved feature. The primary purpose of a convolution is to extract features from the input data.</p></li>
<li><p><strong>Pooling Layer</strong>: Pooling layers are used to reduce the dimensions of the feature maps, thereby reducing the number of parameters and computation in the network. The most common type of pooling is max pooling.</p></li>
<li><p><strong>Fully Connected Layer</strong>: After several convolutional and pooling layers, the final classification is done using one or more fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular neural networks.</p></li>
<li><p><strong>Activation Functions</strong>: Non-linearity is introduced into the CNN using activation functions. The Rectified Linear Unit (ReLU) is the most commonly used activation function in CNNs.</p></li>
</ol>
</section>
<section id="how-cnns-learn-spatial-hierarchies">
<h3>How CNNs Learn Spatial Hierarchies<a class="headerlink" href="#how-cnns-learn-spatial-hierarchies" title="Permalink to this heading">#</a></h3>
<p>CNNs learn spatial hierarchies automatically. The initial layers might learn to detect edges, the next layers learn to detect shapes by combining edges, further layers might detect more complex structures. This ability to learn spatial hierarchies from raw data gives CNNs their power. It allows them to detect complex objects in images by combining simpler features from the earlier layers.</p>
</section>
<section id="advantages-of-cnns">
<h3>Advantages of CNNs<a class="headerlink" href="#advantages-of-cnns" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Parameter Sharing</strong>: A feature detector (filter) that’s useful in one part of the image can be useful in another part of the image <span id="id3">[<a class="reference internal" href="References1.html#id7" title="Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 2012.">Krizhevsky <em>et al.</em>, 2012</a>]</span>.</p></li>
<li><p><strong>Sparsity of Connections</strong>: In each layer, each output value depends only on a small number of input values, making the computation more efficient.</p></li>
</ul>
</section>
<section id="basic-code-implementation">
<h3>Basic Code Implementation<a class="headerlink" href="#basic-code-implementation" title="Permalink to this heading">#</a></h3>
<p>Below, you’ll find a basic Convolutional Neural Network (CNN) structure implemented in TensorFlow. Treat this as a foundational blueprint for your subsequent implementations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span>

<span class="c1"># Define the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="c1"># Add additional convolutional and pooling layers as needed</span>
<span class="c1"># ...</span>

<span class="c1"># Add dense layers for classification</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="c1"># model.add(layers.Dense(10, activation=&#39;softmax&#39;))  # 10 is the number of classes</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>  <span class="c1"># 1 neuron for binary classification</span>


<span class="c1"># Compile and train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="random-forests">
<h2>Random Forests<a class="headerlink" href="#random-forests" title="Permalink to this heading">#</a></h2>
<p>Random Forest is a notable and significant part of machine learning and is commonly used for classification. It can also be used for regression, but its application in classification is more prevalent. Decision Trees are the core components of a Random Forest, so let’s delve into the concepts of Decision Trees <span id="id4">[<a class="reference internal" href="References1.html#id10" title="Leo Breiman. Random forests. Machine learning, 45(1):5–32, 2001.">Breiman, 2001</a>, <a class="reference internal" href="References1.html#id18" title="J. Ross Quinlan. Induction of decision trees. Machine learning, 1(1):81–106, 1986.">Quinlan, 1986</a>]</span>.</p>
<section id="theoretical-foundations">
<h3>Theoretical Foundations<a class="headerlink" href="#theoretical-foundations" title="Permalink to this heading">#</a></h3>
</section>
<section id="ensemble-learning">
<h3>1. <strong>Ensemble Learning</strong><a class="headerlink" href="#ensemble-learning" title="Permalink to this heading">#</a></h3>
<p>Ensemble methods employ multiple learning algorithms to achieve better predictive performance than any individual learning algorithm alone <span id="id5">[<a class="reference internal" href="References1.html#id16" title="Thomas G Dietterich. Ensemble methods in machine learning. In Multiple classifier systems, 1–15. Springer, 2000.">Dietterich, 2000</a>]</span>. The primary principle behind ensemble models is that several weak learners come together to form a strong learner.</p>
</section>
<section id="decision-trees">
<h3>2. <strong>Decision Trees</strong><a class="headerlink" href="#decision-trees" title="Permalink to this heading">#</a></h3>
<p>Decision trees are central to a Random Forest. They split data into subsets based on feature values, recursively producing a decision tree <span id="id6">[<a class="reference internal" href="References1.html#id18" title="J. Ross Quinlan. Induction of decision trees. Machine learning, 1(1):81–106, 1986.">Quinlan, 1986</a>]</span>.</p>
</section>
<section id="bootstrap-aggregating-bagging">
<h3>3. <strong>Bootstrap Aggregating (Bagging)</strong><a class="headerlink" href="#bootstrap-aggregating-bagging" title="Permalink to this heading">#</a></h3>
<p>Random Forests leverage bagging, where multiple dataset subsets are created by drawing samples with replacement. A separate decision tree is built for each of these samples <span id="id7">[<a class="reference internal" href="References1.html#id19" title="Leo Breiman. Bagging predictors. Machine learning, 24(2):123–140, 1996.">Breiman, 1996</a>]</span>.</p>
</section>
<section id="feature-randomness">
<h3>4. <strong>Feature Randomness</strong><a class="headerlink" href="#feature-randomness" title="Permalink to this heading">#</a></h3>
<p>In conventional decision trees, the best feature is chosen to split data at every node. However, Random Forests introduce randomness by selecting a random set of features, then choosing the best split from this subset, ensuring a diverse ensemble of trees.</p>
</section>
<section id="advantages">
<h3>Advantages<a class="headerlink" href="#advantages" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Generalisation</strong>: By combining the predictions of multiple trees, Random Forests tend to generalize better and are less susceptible to overfitting on training data.</p></li>
<li><p><strong>Parallel Processing</strong>: Each decision tree can be built independently, allowing for parallel processing which speeds up the algorithm considerably for large datasets.</p></li>
<li><p><strong>Handling Missing Values</strong>: Random Forests can handle missing values and still produce reasonable predictions.</p></li>
<li><p><strong>Importance Scoring</strong>: They provide an importance score for each feature, aiding in feature selection or interpretability.</p></li>
</ul>
</section>
<section id="implementation-in-python-using-scikit-learn">
<h3>Implementation in Python (Using Scikit-learn)<a class="headerlink" href="#implementation-in-python-using-scikit-learn" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Initialise the model with n_estimators specifying the number of trees in the forest</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># We need to reshape the data in order to be compatible with Random Forest</span>
<span class="n">X_reshaped</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="c1"># Fit the model to your training data</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_reshaped</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict the classes of the test data</span>
<span class="n">X_test_reshaped</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reshaped</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="vision-transformer-vit">
<h2>Vision Transformer (ViT)<a class="headerlink" href="#vision-transformer-vit" title="Permalink to this heading">#</a></h2>
<p>Vision Transformers (ViTs) are a recent breakthrough in the field of deep learning for image processing. They depart from the traditional convolutional neural network (CNN) approach and apply transformers, which were originally designed for natural language processing tasks, to image classification.</p>
<section id="id8">
<h3>Theoretical Foundations<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
</section>
<section id="tokenisation-of-images">
<h3>1. <strong>Tokenisation of Images</strong><a class="headerlink" href="#tokenisation-of-images" title="Permalink to this heading">#</a></h3>
<p>Instead of processing images using convolutions, ViTs divide the image into fixed-size patches, linearly embed them, and then process the resulting sequence of vectors (or tokens) using a transformer.<span id="id9">[<a class="reference internal" href="References1.html#id8" title="Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, and others. An image is worth 16x16 words: transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.">Dosovitskiy <em>et al.</em>, 2020</a>]</span></p>
</section>
<section id="position-embeddings">
<h3>2. <strong>Position Embeddings</strong><a class="headerlink" href="#position-embeddings" title="Permalink to this heading">#</a></h3>
<p>Since the original transformer doesn’t have a notion of the relative positions of tokens, positional embeddings are added to the patch embeddings to retain the positional information.<span id="id10">[<a class="reference internal" href="References1.html#id8" title="Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, and others. An image is worth 16x16 words: transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.">Dosovitskiy <em>et al.</em>, 2020</a>]</span></p>
</section>
<section id="transformer-architecture">
<h3>3. <strong>Transformer Architecture</strong><a class="headerlink" href="#transformer-architecture" title="Permalink to this heading">#</a></h3>
<p>The core of ViT is the transformer architecture, which consists of multiple layers of multi-head self-attention mechanisms and feed-forward neural networks.<span id="id11">[<a class="reference internal" href="References1.html#id8" title="Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, and others. An image is worth 16x16 words: transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.">Dosovitskiy <em>et al.</em>, 2020</a>]</span></p>
</section>
<section id="classification-head">
<h3>4. <strong>Classification Head</strong><a class="headerlink" href="#classification-head" title="Permalink to this heading">#</a></h3>
<p>After processing through the transformer layers, the embedding of the first token (often referred to as the ‘CLS’ token) is used to classify the image.<span id="id12">[<a class="reference internal" href="References1.html#id8" title="Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, and others. An image is worth 16x16 words: transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.">Dosovitskiy <em>et al.</em>, 2020</a>]</span></p>
</section>
<section id="advantages-of-vit">
<h3>Advantages of ViT<a class="headerlink" href="#advantages-of-vit" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Model Transferability</strong>: ViTs pre-trained on large datasets can be fine-tuned on smaller datasets, achieving high performance even when the available labeled data is limited.</p></li>
<li><p><strong>Scalability</strong>: ViTs are more data-hungry compared to CNNs. However, their performance continues to improve as the model size and the amount of data increase, often surpassing other architectures.</p></li>
<li><p><strong>Flexibility</strong>: The transformer architecture isn’t specialized for grid-like data (like images), making ViTs potentially more flexible for varied input data types.</p></li>
</ul>
</section>
<section id="challenges">
<h3>Challenges<a class="headerlink" href="#challenges" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Computational Demand</strong>: ViTs can be computationally intensive, especially when dealing with large images or when the model has many layers.</p></li>
<li><p><strong>Data Requirement</strong>: To achieve optimal performance, ViTs often require more training data compared to CNNs.</p></li>
</ul>
</section>
<section id="implementation">
<h3>Implementation<a class="headerlink" href="#implementation" title="Permalink to this heading">#</a></h3>
<p>The implmentation of Vision Transformer is much more complicated than CNN and Random Forest as there is no built-in functions or layers in the library. However, the following code uses some existing functions like Muliti-head attention to build the transformer block. You don’t need to know the exactly and detailed structure of ViT as it is not required in this course. Please follow the code below for example of implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install this additional Tensorflow package for ViT</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">addons</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install packages needed</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">confusion_matrix</span><span class="p">,</span><span class="n">classification_report</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>

<span class="k">def</span> <span class="nf">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">gelu</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
<span class="k">class</span> <span class="nc">Patches</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Patches</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">extract_patches</span><span class="p">(</span>
            <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
            <span class="n">sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">rates</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">patch_dims</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">patch_dims</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">patches</span>
<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="k">class</span> <span class="nc">PatchEncoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_patches</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PatchEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="n">num_patches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">projection_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="n">num_patches</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">projection_dim</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patch</span><span class="p">):</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">patch</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">encoded</span>

<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="k">def</span> <span class="nf">create_vit_classifier</span><span class="p">():</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="c1"># Augment data.</span>
    <span class="n">augmented</span> <span class="o">=</span> <span class="n">more_data</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="c1"># Create patches.</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">Patches</span><span class="p">(</span><span class="n">patch_size</span><span class="p">)(</span><span class="n">augmented</span><span class="p">)</span>
    <span class="c1"># Encode patches.</span>
    <span class="n">encoded_patches</span> <span class="o">=</span> <span class="n">PatchEncoder</span><span class="p">(</span><span class="n">num_patches</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">)(</span><span class="n">patches</span><span class="p">)</span>

    <span class="c1"># Create multiple layers of the Transformer block.</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">transformer_layers</span><span class="p">):</span>
        <span class="c1"># Layer normalization 1.</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)(</span><span class="n">encoded_patches</span><span class="p">)</span>
        <span class="c1"># Create a multi-head attention layer.</span>
        <span class="n">attention_output</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">key_dim</span><span class="o">=</span><span class="n">projection_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">)(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
        <span class="c1"># Skip connection 1.</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()([</span><span class="n">attention_output</span><span class="p">,</span> <span class="n">encoded_patches</span><span class="p">])</span>
        <span class="c1"># Layer normalization 2.</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)(</span><span class="n">x2</span><span class="p">)</span>
        <span class="c1"># MLP.</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">mlp</span><span class="p">(</span><span class="n">x3</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="n">transformer_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># Skip connection 2.</span>
        <span class="n">encoded_patches</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">()([</span><span class="n">x3</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span>

    <span class="c1"># Create a [batch_size, projection_dim] tensor.</span>
    <span class="n">representation</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)(</span><span class="n">encoded_patches</span><span class="p">)</span>
    <span class="n">representation</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">representation</span><span class="p">)</span>
    <span class="n">representation</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">representation</span><span class="p">)</span>
    <span class="c1"># Add MLP.</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">mlp</span><span class="p">(</span><span class="n">representation</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">=</span><span class="n">mlp_head_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="c1"># Classify outputs.</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)(</span><span class="n">features</span><span class="p">)</span>
    <span class="c1"># Create the Keras model.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="c1">#=========================================================================================================</span>
<span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">),</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseTopKCategoricalAccuracy</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;top-5-accuracy&quot;</span><span class="p">),</span>
        <span class="p">],</span>
    <span class="p">)</span>

    <span class="n">checkpoint_filepath</span> <span class="o">=</span> <span class="s2">&quot;/tmp/checkpoint&quot;</span>
    <span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">checkpoint_filepath</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_callback</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">checkpoint_filepath</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">top_5_accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test top 5 accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">top_5_accuracy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">history</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1">#Can be changed to multi-classed classification</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span><span class="c1">#depends on the size of the image we want</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="mi">72</span>  
<span class="n">patch_size</span> <span class="o">=</span> <span class="mi">6</span>  
<span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">projection_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">transformer_units</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">projection_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">projection_dim</span><span class="p">,</span>
<span class="p">]</span> 
<span class="n">transformer_layers</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mlp_head_units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]</span>  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data augmentation</span>
<span class="n">more_data</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Normalization</span><span class="p">(),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Resizing</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s2">&quot;horizontal&quot;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="n">factor</span><span class="o">=</span><span class="mf">0.02</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span>
            <span class="n">height_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">width_factor</span><span class="o">=</span><span class="mf">0.2</span>
        <span class="p">),</span>
    <span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;more_data&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">more_data</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here vit is your trained model after the training</span>
<span class="n">vit</span> <span class="o">=</span> <span class="n">create_vit_classifier</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run_experiment</span><span class="p">(</span><span class="n">vit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After training the model, you can save the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can always load the model via this line of code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-selection-and-cross-validation">
<h2>Model Selection and Cross-validation<a class="headerlink" href="#model-selection-and-cross-validation" title="Permalink to this heading">#</a></h2>
<p>Cross-validation and model selection are pivotal components in ensuring the robustness of machine learning models. They ensure that our model doesn’t just memorise the training data (overfitting) and that it generalises well to new, unseen data. However, they are some small nuances between this procedure in Deep Learning models (like CNN and ViT) and traditional Machine Learning models (Random Forests)</p>
<section id="deep-learning-models">
<h3>Deep Learning Models:<a class="headerlink" href="#deep-learning-models" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Validation During Training</strong>:</p>
<ul>
<li><p>Deep learning models, particularly when trained on large datasets, often incorporate a validation set during the training process. This is done to monitor the model’s generalization performance and to use mechanisms like early stopping, learning rate annealing based on validation loss, etc.</p></li>
</ul>
</li>
<li><p><strong>Cross-Validation Less Common</strong>:</p>
<ul>
<li><p>Due to the computational intensity and time required to train deep learning models, k-fold cross-validation is less commonly used. Instead, a single hold-out validation set (or sometimes a few different validation sets) is used.</p></li>
</ul>
</li>
<li><p><strong>Model Selection</strong>:</p>
<ul>
<li><p>While the principles of model selection apply to deep learning, the specific approach might be different. Hyperparameter tuning in deep learning might involve methods like random search, Bayesian optimization, or dedicated libraries like Optuna or Ray Tune, instead of just grid search.</p></li>
</ul>
</li>
</ul>
</section>
<section id="traditional-ml-models">
<h3>Traditional ML Models:<a class="headerlink" href="#traditional-ml-models" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Cross-Validation</strong>:</p>
<ul>
<li><p>For many traditional machine learning models, k-fold cross-validation is a standard technique because these models are typically faster to train. Cross-validation gives a more robust estimate of the model’s performance.</p></li>
</ul>
</li>
<li><p><strong>Model Selection</strong>:</p>
<ul>
<li><p>Grid search combined with cross-validation (e.g., <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> in scikit-learn) is a common method for hyperparameter tuning and model selection for traditional algorithms.</p></li>
</ul>
</li>
</ul>
</section>
<section id="overlap-best-practices">
<h3>Overlap &amp; Best Practices:<a class="headerlink" href="#overlap-best-practices" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Despite these general trends, it’s worth noting that there’s overlap. Deep learning models can also be evaluated using cross-validation if computational resources permit. Similarly, traditional ML models can (and do) use validation sets during training, especially for iterative algorithms like gradient boosting machines.</p></li>
<li><p>The choice between using a validation set during training or relying on cross-validation often depends on the dataset’s size, computational resources, and specific project requirements.</p></li>
<li><p>Actually we have included validation procedure in the building of CNN and ViT. Check for code that contains ‘validation or validation split’.</p></li>
</ul>
</section>
<section id="what-is-cross-validation-bishop2006pattern">
<h3>What is Cross-Validation? <span id="id13">[<a class="reference internal" href="References1.html#id4" title="Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning. Volume 4. Springer, 2006.">Bishop and Nasrabadi, 2006</a>]</span><a class="headerlink" href="#what-is-cross-validation-bishop2006pattern" title="Permalink to this heading">#</a></h3>
<p>Cross-validation is a technique to evaluate the performance of a model by splitting the dataset into a training set and a validation set multiple times. The most common method is k-fold cross-validation.</p>
</section>
<section id="k-fold-cross-validation-bishop2006pattern">
<h3>K-Fold Cross-Validation <span id="id14">[<a class="reference internal" href="References1.html#id4" title="Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning. Volume 4. Springer, 2006.">Bishop and Nasrabadi, 2006</a>]</span><a class="headerlink" href="#k-fold-cross-validation-bishop2006pattern" title="Permalink to this heading">#</a></h3>
<p>In k-fold cross-validation, the training data is randomly partitioned into k equal-sized subsets. Of the k subsets, a single subset is retained as validation data, and the remaining k-1 subsets are used as training data. The cross-validation process is repeated k times, with each of the k subsets used exactly once as validation data. The k results can then be averaged to produce a single estimation.</p>
<p>The following code is a example of K-Fold CV for Random Forest model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="c1"># Assuming `model` is your sklearn model and `X` and `y` are your data</span>
<span class="c1"># Perform 5-fold cross-validation</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_reshaped</span><span class="p">,</span> <span class="n">y_train_balanced</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Print the mean of the cross-validation scores</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean cross-validation score: &quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-selection">
<h2>Model Selection<a class="headerlink" href="#model-selection" title="Permalink to this heading">#</a></h2>
<p>Model selection involves choosing the best model from a set of models based on performance. The model with the best cross-validation score is typically selected.</p>
<section id="grid-search">
<h3>Grid Search<a class="headerlink" href="#grid-search" title="Permalink to this heading">#</a></h3>
<p>A popular technique for model selection is grid search. Grid search involves:</p>
<ul class="simple">
<li><p>Specifying a subset of the hyperparameter space.</p></li>
<li><p>Training a model for each hyperparameter combination.</p></li>
<li><p>Evaluating each model using cross-validation.</p></li>
<li><p>Selecting the model with the best cross-validation performance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Example for a hypothetical model&#39;s hyperparameters</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters: &quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: &quot;</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-data">Loading the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutional-neural-networks-cnn">Convolutional Neural Networks (CNN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-cnns">Introduction to CNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-cnn-for-image-data">Why CNN for Image Data?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-components-of-cnn">Key Components of CNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-cnns-learn-spatial-hierarchies">How CNNs Learn Spatial Hierarchies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-of-cnns">Advantages of CNNs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-code-implementation">Basic Code Implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests">Random Forests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-learning">1. <strong>Ensemble Learning</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-trees">2. <strong>Decision Trees</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap-aggregating-bagging">3. <strong>Bootstrap Aggregating (Bagging)</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-randomness">4. <strong>Feature Randomness</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages">Advantages</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-in-python-using-scikit-learn">Implementation in Python (Using Scikit-learn)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vision-transformer-vit">Vision Transformer (ViT)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Theoretical Foundations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation-of-images">1. <strong>Tokenisation of Images</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#position-embeddings">2. <strong>Position Embeddings</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformer-architecture">3. <strong>Transformer Architecture</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-head">4. <strong>Classification Head</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-of-vit">Advantages of ViT</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges">Challenges</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection-and-cross-validation">Model Selection and Cross-validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-models">Deep Learning Models:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#traditional-ml-models">Traditional ML Models:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overlap-best-practices">Overlap &amp; Best Practices:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-cross-validation-bishop2006pattern">What is Cross-Validation? <span class="xref cite">bishop2006pattern</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-fold-cross-validation-bishop2006pattern">K-Fold Cross-Validation <span class="xref cite">bishop2006pattern</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search">Grid Search</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michel Tsamados/Weibin Chen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>