{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll-out on a Full Image\n",
    "ðŸ“˜ **Interactive Version**: For a hands-on experience with this chapter's content, access the interactive notebook in [Google Colab](https://drive.google.com/file/d/1ZPRyzfhLtQcsFJEWGtoayVFeI-8WR8oq/view?usp=sharing).\n",
    "### Introduction\n",
    "Applying machine learning models to entire, full-sized imagesâ€”especially in the realm of image processingâ€”presents a distinct set of challenges and opportunities. Such a \"roll-out\" doesn't just involve stretching a model's capabilities across larger pixel dimensions; it tests the model's capacity to consistently and correctly generate outputs, be it segmentation or classification maps, across varying regions of an image.\n",
    "\n",
    "### Preparation\n",
    "- Here, we need to process the image to be rolled-out into the shape that is compatible to our model input shape. For example, the model input shape is `(3, 3, 21)`. The below code is for processing the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "# Function to convert coordinates from WGS84 to EASE-Grid 2.0 projection\n",
    "def WGS84toEASE2(lon, lat):\n",
    "    # Initialise the EASE-Grid 2.0 projection\n",
    "    proj_EASE2 = pyproj.Proj(\"+proj=laea +lon_0=0 +lat_0=90 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\")\n",
    "    # Initialise the WGS84 projection\n",
    "    proj_WGS84 = pyproj.Proj(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "    # Transform the coordinates from WGS84 to EASE-Grid 2.0\n",
    "    x, y = pyproj.transform(proj_WGS84, proj_EASE2, lon, lat)\n",
    "    return x, y\n",
    "\n",
    "# Directory setup for data files\n",
    "directory = 'path_to_data_folder'\n",
    "\n",
    "# Load in geolocation data from a NetCDF file\n",
    "geolocation = netCDF4.Dataset(directory+'/geo_coordinates.nc')\n",
    "lat = geolocation.variables['latitude'][:]\n",
    "lon = geolocation.variables['longitude'][:]\n",
    "\n",
    "# Load in radiance data for a specific band (Band Oa01) from a NetCDF file\n",
    "Band_Oa01 = netCDF4.Dataset(directory+'/Oa01_radiance.nc')\n",
    "Oa01_Radiance = Band_Oa01.variables['Oa01_radiance'][:]\n",
    "\n",
    "# Convert the longitude and latitude to EASE-Grid 2.0 coordinates\n",
    "X, Y = WGS84toEASE2(lon, lat)\n",
    "\n",
    "# Load in additional instrument data from a NetCDF file\n",
    "OLCI_file_p = directory\n",
    "instrument_data = netCDF4.Dataset(OLCI_file_p+'/instrument_data.nc')\n",
    "solar_flux = instrument_data.variables['solar_flux'][:]\n",
    "solar_flux_Band_Oa01 = solar_flux[0]  # Solar flux for Band Oa01\n",
    "detector_index = instrument_data.variables['detector_index'][:]\n",
    "\n",
    "# Load in tie geometries (e.g., Solar Zenith Angle) from a NetCDF file\n",
    "tie_geometries = netCDF4.Dataset(OLCI_file_p+'/tie_geometries.nc')\n",
    "SZA = tie_geometries.variables['SZA'][:]\n",
    "\n",
    "# Initialise lists to store bands and patches\n",
    "Bands = []\n",
    "Patches = []\n",
    "\n",
    "# Calculate the number of patches (nx, ny)\n",
    "nx = X.shape[0] - 2\n",
    "ny = X.shape[1] - 2\n",
    "q = 0\n",
    "\n",
    "# Process each band\n",
    "for i in range(1, 22):  # Loop through 21 bands\n",
    "    solar_flux_Band_Oa01 = solar_flux[q]\n",
    "    print(i)\n",
    "    bandnumber = '%02d' % (i)\n",
    "    Band_Oa_temp = netCDF4.Dataset(directory+'/Oa'+bandnumber+'_radiance.nc')\n",
    "\n",
    "    width = instrument_data.dimensions['columns'].size\n",
    "    height = instrument_data.dimensions['rows'].size\n",
    "\n",
    "    # Calculate the Top of Atmosphere Bidirectional Reflectance Factor (TOA BRF)\n",
    "    TOA_BRF = np.zeros((height, width), dtype='float32')\n",
    "    angle = np.zeros((TOA_BRF.shape[0], TOA_BRF.shape[1]))\n",
    "    for x in range(TOA_BRF.shape[1]):\n",
    "        angle[:, x] = SZA[:, int(x / 64)]\n",
    "\n",
    "    oa = Band_Oa_temp.variables['Oa' + bandnumber + '_radiance'][:]\n",
    "    TOA_BRF = np.zeros((height, width), dtype=float)\n",
    "    TOA_BRF = np.pi * np.asarray(oa) / solar_flux_Band_Oa01[detector_index] / np.cos(np.radians(angle))\n",
    "\n",
    "    Bands.append(TOA_BRF)\n",
    "    # Extract patches of size 3x3 from the TOA BRF and reshape for further processing\n",
    "    Patches.append(image.extract_patches_2d(np.array(TOA_BRF), (3, 3)).reshape(nx, ny, 3, 3))\n",
    "    q += 1\n",
    "\n",
    "# Convert the list of patches to a NumPy array and reshape for machine learning model input\n",
    "Patches_array = np.asarray(Patches)\n",
    "x_test_all = np.moveaxis(Patches_array, 0, -1).reshape(Patches_array.shape[1] * Patches_array.shape[2], 3, 3, 21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Application\n",
    "In this phase, the trained model processes the entire image, generating outputs that classify the different regions into respective categories such as sea-ice and leads. Let's say your saved model is called `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the full image\n",
    "y_pred=model.predict(x_test_all, batch_size = 250)\n",
    "y_pred1 = np.argmax(y_pred,axis = 1)\n",
    "# Reshape it for display\n",
    "map1=y_pred1.reshape(Pathches_array.shape[1], Pathches_array.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results\n",
    "Visual inspection plays a crucial role here. By juxtaposing the model-generated classified images against the original, we can discern the model's aptitude in retaining the intrinsic spatial structures and patterns of the original image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter the view setting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 600\n",
    "# Show the map\n",
    "plt.imshow(map1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Below is a full code of roll-out in a loop manner. A list of filenames of the files that contain the OLCI netCDF files is needed. The below code is a loop that go through each OLCI image that you want to roll-out. You can edit the list of filenames as required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "# Function to convert coordinates from WGS84 to EASE-Grid 2.0 projection\n",
    "def WGS84toEASE2(lon, lat):\n",
    "    # Initialise the EASE-Grid 2.0 projection (Lambert Azimuthal Equal Area projection)\n",
    "    proj_EASE2 = pyproj.Proj(\"+proj=laea +lon_0=0 +lat_0=90 +x_0=0 +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\")\n",
    "    # Initialise the WGS84 projection\n",
    "    proj_WGS84 = pyproj.Proj(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "    # Transform the coordinates from WGS84 to EASE-Grid 2.0\n",
    "    x, y = pyproj.transform(proj_WGS84, proj_EASE2, lon, lat)\n",
    "    return x, y\n",
    "\n",
    "# Directory setup for data files\n",
    "directory = folder_name\n",
    "directory = '/lustre/home/zcakwc1/project/03/' + directory + '/' + directory\n",
    "\n",
    "# Load in geolocation data from a NetCDF file\n",
    "geolocation = netCDF4.Dataset(directory+'/geo_coordinates.nc')\n",
    "lat = geolocation.variables['latitude'][:]\n",
    "lon = geolocation.variables['longitude'][:]\n",
    "\n",
    "# Load in radiance data for a specific band (Band Oa01) from a NetCDF file\n",
    "Band_Oa01 = netCDF4.Dataset(directory+'/Oa01_radiance.nc')\n",
    "Oa01_Radiance = Band_Oa01.variables['Oa01_radiance'][:]\n",
    "\n",
    "# Convert the longitude and latitude to EASE-Grid 2.0 coordinates\n",
    "X, Y = WGS84toEASE2(lon, lat)\n",
    "\n",
    "# Load in additional instrument data from a NetCDF file\n",
    "OLCI_file_p = directory\n",
    "instrument_data = netCDF4.Dataset(OLCI_file_p+'/instrument_data.nc')\n",
    "solar_flux = instrument_data.variables['solar_flux'][:]\n",
    "solar_flux_Band_Oa01 = solar_flux[0]  # Solar flux for Band Oa01\n",
    "detector_index = instrument_data.variables['detector_index'][:]\n",
    "\n",
    "# Load in tie geometries (e.g., Solar Zenith Angle) from a NetCDF file\n",
    "tie_geometries = netCDF4.Dataset(OLCI_file_p+'/tie_geometries.nc')\n",
    "SZA = tie_geometries.variables['SZA'][:]\n",
    "\n",
    "# Initialise lists to store bands and patches\n",
    "Bands = []\n",
    "Patches = []\n",
    "\n",
    "# Calculate the number of patches (nx, ny)\n",
    "nx = X.shape[0] - 2\n",
    "ny = X.shape[1] - 2\n",
    "q = 0\n",
    "\n",
    "# Process each band\n",
    "for i in range(1, 22):  # Loop through 21 bands\n",
    "    solar_flux_Band_Oa01 = solar_flux[q]\n",
    "    print(i)\n",
    "    bandnumber = '%02d' % (i)\n",
    "    Band_Oa_temp = netCDF4.Dataset(directory+'/Oa'+bandnumber+'_radiance.nc')\n",
    "\n",
    "    width = instrument_data.dimensions['columns'].size\n",
    "    height = instrument_data.dimensions['rows'].size\n",
    "\n",
    "    # Calculate the Top of Atmosphere Bidirectional Reflectance Factor (TOA BRF)\n",
    "    TOA_BRF = np.zeros((height, width), dtype='float32')\n",
    "    angle = np.zeros((TOA_BRF.shape[0], TOA_BRF.shape[1]))\n",
    "    for x in range(TOA_BRF.shape[1]):\n",
    "        angle[:, x] = SZA[:, int(x / 64)]\n",
    "\n",
    "    oa = Band_Oa_temp.variables['Oa' + bandnumber + '_radiance'][:]\n",
    "    TOA_BRF = np.zeros((height, width), dtype=float)\n",
    "    TOA_BRF = np.pi * np.asarray(oa) / solar_flux_Band_Oa01[detector_index] / np.cos(np.radians(angle))\n",
    "\n",
    "    Bands.append(TOA_BRF)\n",
    "    # Extract patches of size 3x3 from the TOA BRF and reshape for further processing\n",
    "    Patches.append(image.extract_patches_2d(np.array(TOA_BRF), (3, 3)).reshape(nx, ny, 3, 3))\n",
    "    q += 1\n",
    "\n",
    "# Convert the list of patches to a NumPy array and reshape for machine learning model input\n",
    "Patches_array = np.asarray(Patches)\n",
    "x_test_all = np.moveaxis(Patches_array, 0, -1).reshape(Patches_array.shape[1] * Patches_array.shape[2], 3, 3, 21)\n",
    "\n",
    "\n",
    "    y_pred=model1.predict(x_test_all, batch_size = 250)\n",
    "    y_pred1 = np.argmax(y_pred,axis = 1)\n",
    "\n",
    "    map1=y_pred1.reshape(Pathches_array.shape[1], Pathches_array.shape[2])\n",
    "\n",
    "    np.save('map{}'.format(q),map1)\n",
    "    q = q + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollout on a Small Region\n",
    "You can also try your model on a small sub-region of a full image. For example, we do the rollout on a region where we used IRIS to classify. The overall logic is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images are in numpy array format\n",
    "image = np.load(path + 'chunk_3_band_21.npy')\n",
    "\n",
    "# Extracting the mask_area values from the JSON\n",
    "x1, y1, x2, y2 = [100, 700, 300, 1000]\n",
    "\n",
    "# Extracting the region of interest (ROI) from the image\n",
    "roi = image[y1:y2, x1:x2]\n",
    "\n",
    "# roi is your data with shape (300, 200, 21)\n",
    "patches = []\n",
    "\n",
    "# Iterate over the height and width of the roi, excluding the border pixels\n",
    "for i in range(1, roi.shape[0] - 1):\n",
    "    for j in range(1, roi.shape[1] - 1):\n",
    "        # Extract a (3, 3, 21) patch centered around the pixel (i, j)\n",
    "        patch = roi[i-1:i+2, j-1:j+2, :]\n",
    "        patches.append(patch)\n",
    "\n",
    "# Convert the list of patches to a numpy array\n",
    "x_test_all = np.array(patches)\n",
    "\n",
    "y_pred=model1.predict(x_test_all, batch_size = 250)\n",
    "y_pred1 = np.argmax(y_pred,axis = 1)\n",
    "map1=y_pred1.reshape(Pathches_array.shape[1], Pathches_array.shape[2])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}